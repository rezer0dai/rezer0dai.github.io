---
title: "Experimental techniques for Reinforcement Learning"
tags:
  - rewheeler
  - reinforcement learning
  - ai
  - research
---

{% include toc %}

# Project REWheeler

Replay Buffer oriented!

## HER : request for research
*Hindsight Experience Replay (**HER**)* : reinforcement learning algorithm that can learn from failure, which can learn successful policies on robotics problems from only sparse rewards.
<br/>In my words even if agent fails to achieve goal (goal-a), it achieves somethings. And that something (goal-b) will be not scattered, but will be evaluated with respect to policy and recorded state-action pairs we taken to achieve that goal-b, but this time our objective will be not originally intended to reach goal-a but goal-b instead. This way we can introduce more closely related learning signal to goal based environment, while avoiding overcomplicated hand engineered reward functions (example 1/0 signal ~ goal was achieved or not).

However this technique has some potential limitations. For example we can not simply use n-step estimators when it comes to [td-error](http://boris-belousov.net/2017/08/10/td-advantage-bellman/), which seeks balance between bias vs variance. This and some others improvements was highlighted at HER specific [OpenAi Rquest for research](https://openai.com/blog/ingredients-for-robotics-research/#requestsforresearchheredition) and i am trying to address some of those in this post and project itself.

